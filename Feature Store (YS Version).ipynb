{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b915e04d-0d81-4c9c-a872-e700a1c39863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role: arn:aws:iam::767397858887:role/LabRole\n",
      "SageMaker S3 Bucket: sagemaker-us-east-1-767397858887\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Initialize SageMaker (SM) and Boto3 clients\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "s3_bucket_name = sagemaker_session.default_bucket() # Or specify your own bucket\n",
    "prefix = 'pisa-feature-store'\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "featurestore_runtime = boto3.client('sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"SageMaker S3 Bucket: {s3_bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8ec76-0712-42df-b066-8ff97665e172",
   "metadata": {},
   "source": [
    "Design Feature Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b1f8fe-874c-47cd-85cd-43272eb434ca",
   "metadata": {},
   "source": [
    "Features can be logically separated into groups based on their source and how frequently they might be updated.\n",
    "This makes the system more modular. For example, demographic data is static, while academic performance might be updated annually.\n",
    "\n",
    "I'll use CNTSTUID as the `record_identifier_name`, and add an event_time for each record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca895257-2bee-48df-8c16-7e97e93612e3",
   "metadata": {},
   "source": [
    "# Feature Engineering & Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b96a33-178e-4fae-a6f8-e56674509e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load & Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728d718b-eb8a-46aa-982d-8f5ef2555142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165/734207100.py:1: DtypeWarning: Columns (26,29,30,31,32,33,34,35,36,37,38,68,69,70,71,72,73,78,135,136,137,138,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,484,485,486,487,488,489,490,491,492,642,643,644,659,660,661,662,683,716,807) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('s3://aai540group5/us_df.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('s3://aai540group5/us_df.csv')\n",
    "\n",
    "# Use CNTSTUID as student ID\n",
    "df['student_id'] = df['CNTSTUID'].astype(str)\n",
    "# Add an event time column\n",
    "current_time_sec = int(round(time.time()))\n",
    "df['event_time'] = pd.Series([current_time_sec] * len(df), dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72effdd-7c2d-4336-bfe1-fa0aa31916f7",
   "metadata": {},
   "source": [
    "## Feature Engineering: Academic Performance - use PCA to deal with multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ac69fe-0494-440a-b213-3439496b70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg PV scores for each subject (as was done in EDA)\n",
    "pv_subjects = ['MATH', 'READ', 'SCIE', 'SCEP', 'SCED', 'SCID', 'SKCO', 'SKPE', 'SSPH', 'SSLI', 'SSES']\n",
    "pv_avg_cols = []\n",
    "for subject in pv_subjects:\n",
    "    pv_cols = [col for col in df.columns if col.startswith(f'PV') and subject in col]\n",
    "    avg_col_name = f'PV_AVG_{subject}'\n",
    "    if pv_cols:\n",
    "        df[avg_col_name] = df[pv_cols].mean(axis=1)\n",
    "        pv_avg_cols.append(avg_col_name)\n",
    "\n",
    "# Handle multicollinearity with PCA to get a composite 'academic_performance_index'\n",
    "pca_input_df = df[pv_avg_cols].dropna()\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(pca_input_df)\n",
    "pca = PCA(n_components=1)\n",
    "principal_components = pca.fit_transform(scaled_features)\n",
    "# Add new PCA feature back into main DF\n",
    "df['academic_performance_index'] = pd.Series(principal_components.flatten(), index=pca_input_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d36a2-cc05-4134-a7d6-8e23c1eb880c",
   "metadata": {},
   "source": [
    "## Create & Ingest Feature Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da0f34-8a03-4c2f-9583-28bf91600a47",
   "metadata": {},
   "source": [
    "Feature Group 1: Student Demographics & Socioeconomic Status (SES):\n",
    "This feature group stores static data about each student, such as age, grade, and gender, and socioeconomic background indicators. This information rarely changes, so separating it into its own group is an efficient design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e8d7ab2-e352-49ad-8a88-7711368ae1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_ingest_fg(fg_name, fg_dataframe, sagemaker_session):\n",
    "    \"\"\"\n",
    "    Create a SageMaker Feature Group and ingest data (idempotent).\n",
    "    \n",
    "    Uses module-level s3_bucket_name, prefix, and role variables\n",
    "    \"\"\"\n",
    "    # Instantiate the SageMaker (SM) FeatureGroup (FG) object\n",
    "    fg = FeatureGroup(name=fg_name, sagemaker_session=sagemaker_session)\n",
    "    \n",
    "    # Load schema definitions - automatically infer feature schema (names & data types) from the pandas DF\n",
    "    fg.load_feature_definitions(data_frame=fg_dataframe)\n",
    "    \n",
    "    # Create FG & Ingest Data\n",
    "    try:\n",
    "        print(f\"Creating feature group: {fg_name}...\")\n",
    "        \n",
    "        # Create FG in the SageMaker Feature Store backend\n",
    "        fg.create(\n",
    "            s3_uri=f\"s3://{s3_bucket_name}/{prefix}\",    # S3 path for the offline store (long-term storage, batch inference)\n",
    "            record_identifier_name=\"student_id\",         # Unique identifier for each record\n",
    "            event_time_feature_name=\"event_time\",        # Tracks timestamp of the feature data\n",
    "            role_arn=role,                               # IAM role with necessary permissions\n",
    "            enable_online_store=True                     # Enable the online store (for low-latency, real-time inference)\n",
    "        )\n",
    "        \n",
    "        # Get the low-level boto3 client and use its waiter to confirm the resource is active\n",
    "        print(\"Waiting for Feature Group to become active...\")\n",
    "        sagemaker_session.sagemaker_client.get_waiter('feature_group_created').wait(\n",
    "            FeatureGroupName=fg_name\n",
    "        )\n",
    "        \n",
    "    except ClientError as e:\n",
    "        # If the FG already exists, the 'ResourceInUse' error is thrown\n",
    "        if e.response['Error']['Code'] == 'ResourceInUse':\n",
    "            print(f\"{fg_name} already exists\")\n",
    "        else:\n",
    "            # Raise any other errors\n",
    "            raise\n",
    "    \n",
    "    # Ingest data from DataFrame into Feature Group\n",
    "    print(f\"Ingesting {len(fg_dataframe):,} records...\")\n",
    "    fg.ingest(\n",
    "        data_frame=fg_dataframe, \n",
    "        max_workers=3,    # Number of parallel workers for ingestion\n",
    "        wait=True         # Wait for ingestion to complete before returning\n",
    "    )\n",
    "    print(f\"Ingestion complete\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc99c1-5d25-47d3-a240-53a83ba2cdd0",
   "metadata": {},
   "source": [
    "Demographics & Socioeconomic Status Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e815dc-6a3a-4b68-a297-318d21474db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature group: student-demographics-ses-fg...\n",
      "student-demographics-ses-fg already exists\n",
      "Ingesting 32,293 records...\n",
      "Ingestion complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for FG\n",
    "# 'student_id' is the unique key, & 'event_time' tracks when the data was recorded\n",
    "demo_ses_df = df[[\n",
    "    'student_id', 'event_time',\n",
    "    'AGE', 'GRADE', 'ST004D01T',        # Demographics features\n",
    "    'ESCS', 'HOMEPOS', 'WEALTH'         # Socioeconomic Status (SES) indicators\n",
    "]].dropna()  # Remove any rows with missing values\n",
    "\n",
    "create_and_ingest_fg('student-demographics-ses-fg', demo_ses_df, sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a306c9d-a4ff-4c54-bd1f-464259bec46f",
   "metadata": {},
   "source": [
    "Academic Performance Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24923c78-b03b-474d-a767-70e7468746f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contains the computed academic performance index\n",
    "performance_df = df[['student_id', 'event_time', 'academic_performance_index']].dropna()\n",
    "\n",
    "create_and_ingest_fg('student-performance-fg', performance_df, sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313e4f6-b47c-4ebc-bb9c-268292c8723b",
   "metadata": {},
   "source": [
    "Student Wellbeing Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ff339-74ab-4b6c-af9a-dba5f66df73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature group: student-wellbeing-fg...\n",
      "student-wellbeing-fg already exists\n",
      "Ingesting 25,141 records...\n",
      "Ingestion complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selected features based on initial EDA which identified them as having high predictive power\n",
    "wellbeing_features = [\n",
    "    'student_id',       # Record identifier\n",
    "    'event_time',       # Event timestamp\n",
    "    'BELONG',           # Student's sense of belonging at school\n",
    "    'unfairteacher',    # Index of perceived unfairness from teachers\n",
    "    'SCIEEFF',          # Self-efficacy in science\n",
    "    'DISCLISCI',        # Disciplinary climate in science classes\n",
    "    'MOTIVAT',          # Achievement motivation\n",
    "    'PARED',            # Parental emotional support\n",
    "    'TEACHSUP',         # Teacher support\n",
    "    'EMOSUPS'           # Emotional support\n",
    "]\n",
    "\n",
    "# Create new DataFrame with only selected wellbeing features\n",
    "wellbeing_df = df[wellbeing_features].dropna()\n",
    "\n",
    "create_and_ingest_fg('student-wellbeing-fg', wellbeing_df, sagemaker_session)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd06587-52e3-4eb8-b7c4-6e180be4426d",
   "metadata": {},
   "source": [
    "Target Variable Feature Group (Anxiety Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58a6221c-1799-4891-88d4-c7b9a3c1a0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety Level Encoding (for model interpretation):\n",
      "  high → 0\n",
      "  low → 1\n",
      "  medium → 2\n",
      "\n",
      "Creating feature group: student-anxiety-target-fg...\n",
      "student-anxiety-target-fg already exists\n",
      "Ingesting 35,565 records...\n",
      "Ingestion complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare target variable with label encoding for ML model compatibility\n",
    "target_df = df[['student_id', 'event_time', 'ANX_BAND_Q3_US']].dropna().copy()  # copy() avoids SettingWithCopyWarning\n",
    "\n",
    "# Encode categorical anxiety levels to numeric values\n",
    "# This is necessary as most ML algorithms require numeric inputs\n",
    "le = LabelEncoder()\n",
    "target_df['anxiety_level_encoded'] = le.fit_transform(target_df['ANX_BAND_Q3_US'])\n",
    "\n",
    "# Store & display encoding for model interpretation\n",
    "print(\"Anxiety Level Encoding (for model interpretation):\")\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"  {label} → {i}\")\n",
    "print()\n",
    "\n",
    "# Select only required columns for ingestion\n",
    "target_ingest_df = target_df[['student_id', 'event_time', 'anxiety_level_encoded']]\n",
    "\n",
    "create_and_ingest_fg('student-anxiety-target-fg', target_ingest_df, sagemaker_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af631073-80ec-445f-bda1-a06ff4285151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Group Summary:\n",
      "  • Demographics & SES: 32,293 records\n",
      "  • Academic Performance: 36,824 records\n",
      "  • Student Wellbeing: 25,141 records\n",
      "  • Anxiety Target: 35,565 records\n"
     ]
    }
   ],
   "source": [
    "# Summary of created feature groups\n",
    "print(\"\\nFeature Group Summary:\")\n",
    "print(f\"  • Demographics & SES: {len(demo_ses_df):,} records\")\n",
    "print(f\"  • Academic Performance: {len(performance_df):,} records\")\n",
    "print(f\"  • Student Wellbeing: {len(wellbeing_df):,} records\")\n",
    "print(f\"  • Anxiety Target: {len(target_ingest_df):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025c7db-6862-46f4-a28e-eb31836dcb50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
